{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este cuaderno explica cómo utilizar LangChain con Azure OpenAI.\n",
    "\n",
    "La API de Azure OpenAI es compatible con la API de OpenAI. El paquete de Python \"openai\" facilita el uso tanto de OpenAI como de Azure OpenAI. Puedes llamar a Azure OpenAI de la misma manera que llamas a OpenAI, con las excepciones que se mencionan a continuación.\n",
    "\n",
    "**Configuración de la API**\n",
    "\n",
    "Puedes configurar el paquete \"openai\" para usar Azure OpenAI utilizando variables de entorno. A continuación se muestra un ejemplo para entornos bash:\n",
    "\n",
    "```python\n",
    "# Set this to `azure`\n",
    "export OPENAI_API_TYPE=azure\n",
    "# The API version you want to use: set this to `2022-12-01` for the released version.\n",
    "export OPENAI_API_VERSION=2022-12-01\n",
    "# The base URL for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export OPENAI_API_BASE=https://your-resource-name.openai.azure.com\n",
    "# The API key for your Azure OpenAI resource.  You can find this in the Azure portal under your Azure OpenAI resource.\n",
    "export OPENAI_API_KEY=<your Azure OpenAI API key>\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Despliegues**\n",
    "\n",
    "Con Azure OpenAI, puedes configurar tus propios despliegues de los modelos comunes GPT-3 y Codex. Al llamar a la API, necesitas especificar el despliegue que deseas utilizar.\n",
    "\n",
    "Supongamos que el nombre de tu despliegue es gpt-35-turbo. En la API de Python de OpenAI, puedes especificar este despliegue utilizando el parámetro \"engine\". Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"gpt-35-turbo\",\n",
    "    prompt=\"Esta es una historia \",\n",
    "    max_tokens=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entre dos amigas'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].text # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". (laughing)\n",
      "\n",
      "I'm trying to remember the one that I said earlier. God, I don't even remember. What did one astronaut say to the other astronaut when he was lonely?\n",
      "\n",
      "I don't know.\n",
      "\n",
      "I need my space. (laughing)\n",
      "\n",
      "That's a good one. That's a good one.\n",
      "\n",
      "I like that one.\n",
      "\n",
      "I like that one. (laughing)\n",
      "\n",
      "That was a good one.\n",
      "\n",
      "That was really good.\n",
      "\n",
      "That was really good.\n",
      "\n",
      "I'm glad that I could bring some joy into your life with that one.\n",
      "\n",
      "I love that.\n",
      "\n",
      "Yeah, I know, I know.\n",
      "\n",
      "And last, but not least, what is your biggest goal for the rest of this year?\n",
      "\n",
      "Ooh, biggest goal for the rest of this year? I think it is continuing to grow my private practice. It's something that I really enjoy doing. I love working with my clients. I love supporting them and helping them reach their various goals. I also really enjoy creating content, so I wanna continue doing that. I wanna continue building my online presence, my brand, and just continue to grow in that way. So that's my biggest goal for the rest of the year.\n",
      "\n",
      "That's awesome. That's really great. And we'll be"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\". (laughing)\\n\\nI'm trying to remember the one that I said earlier. God, I don't even remember. What did one astronaut say to the other astronaut when he was lonely?\\n\\nI don't know.\\n\\nI need my space. (laughing)\\n\\nThat's a good one. That's a good one.\\n\\nI like that one.\\n\\nI like that one. (laughing)\\n\\nThat was a good one.\\n\\nThat was really good.\\n\\nThat was really good.\\n\\nI'm glad that I could bring some joy into your life with that one.\\n\\nI love that.\\n\\nYeah, I know, I know.\\n\\nAnd last, but not least, what is your biggest goal for the rest of this year?\\n\\nOoh, biggest goal for the rest of this year? I think it is continuing to grow my private practice. It's something that I really enjoy doing. I love working with my clients. I love supporting them and helping them reach their various goals. I also really enjoy creating content, so I wanna continue doing that. I wanna continue building my online presence, my brand, and just continue to grow in that way. So that's my biggest goal for the rest of the year.\\n\\nThat's awesome. That's really great. And we'll be\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Azure OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Create an instance of Azure OpenAI\n",
    "# Replace the deployment name with your own\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    model_name=\"gpt-35-turbo\",  # type: ignore\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    streaming=True\n",
    ") # type: ignore\n",
    "\n",
    "# Run the LLM\n",
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "También podemos imprimir el LLM y ver su impresión personalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAzureOpenAI\u001b[0m\n",
      "Params: {'deployment_name': 'gpt-35-turbo', 'model_name': 'gpt-35-turbo', 'temperature': 0.7, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
