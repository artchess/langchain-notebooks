{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen diferentes modelos:\n",
    "\n",
    "***LLMs***\n",
    "\n",
    "Large Language Models (LLMs) Obtienen una cadena de texto como input y luego regresan una cadena de texto como output\n",
    "\n",
    "***Chat Models***\n",
    "\n",
    "Estos modelos generalmente cuentan con el respaldo de un modelo de lenguaje, pero sus API están más estructuradas. Específicamente, estos modelos toman una lista de mensajes de chat como entrada y devuelven un mensaje de chat como resultado.\n",
    "\n",
    "***Text Embedding Models*** (modelo de inserción de texto)\n",
    "\n",
    "Estos modelos toman texto como entrada y devuelven una lista de números decimales.\n",
    "\n",
    "LangChain proporciona una interfaz estándar para los modelos. Esto permite cambiar fácilmente entre modelos. Por ejemplo OpenAi (un envoltorio para el modelo de lenguaje de OpenAI) y ChatOpenAI (un envoltorio para el modelo de chat de OpenAI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI() # type: ignore\n",
    "chat_model = ChatOpenAI() # type: ignore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text` -> `text` interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHi there!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"say hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict(\"say hi!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`messages` -> `message` interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nRobot: Hi there!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "llm.predict_messages([HumanMessage(content=\"say hi!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello there!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict_messages([HumanMessage(content=\"say hi!\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los Modelos de Lenguaje de Gran Escala (LLMs) son un componente central de LangChain. LangChain no es un proveedor de LLMs, sino que proporciona una interfaz estándar a través de la cual puedes interactuar con una variedad de LLMs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La clase LLM de LangChain.**\n",
    "\n",
    "Hay muchos provedores de LLM (OpenAi, Cohere, Hugging Face, etc), la clase LLM de LangChain esta diseñada para proveer una estandarización de la interfaz para todos ellos. Nos enfocaremos en la funcionalidad general de la clase LLM. Para detalles de como utilizar un envoltorio específico de LLM ir a [How-to Section](https://python.langchain.com/en/latest/modules/models/llms/how_to_guides.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-ada-001\", n=2, best_of=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Text**: La funcionalidad más básica de un LLM es la habilidad de llamarlo, pasarle un string y obtener de vuelta otro string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Tell me a joke\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate**: De manera más amblia, puedes llamarlo con una lista de entradas y obtener una respuesta más completa que solo el texto. Esta respuesta incluye cosas como múltiples respuestas principales, así como información específica del proveedor de LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_result = llm.generate([\"Tell me a joke\", \"Tell me a poem\"]*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_result.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text='\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side.', generation_info={'finish_reason': None, 'logprobs': None}),\n",
       " Generation(text='\\n\\nWhy did the chicken cross the road?\\n\\nTo get to the other side.', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Generation(text='\\n\\nNo one ever comes\\n\\nTo the party you left\\n\\nOnly the memories\\n\\nOf your loved ones remain\\n\\nAs they laugh and dance\\n\\nAnd the love they once felt\\n\\n remains\\n\\nIn their hearts they still tell\\n\\nA story of a time soon\\n\\nWhen love was strong\\n\\nAnd everyone came together\\n\\nFor a beautiful event\\n\\nThat will be remembered\\n\\nFor a moment of pure joy\\n\\nAnd all you left behind\\n\\n remain\\n\\nYour friends and family\\n\\nAnd they keep going strong\\n\\nThe memories they make\\n\\nOf the time they shared\\n\\nAre still with them today', generation_info={'finish_reason': 'stop', 'logprobs': None}),\n",
       " Generation(text='\\n\\nHow could I be happy\\n\\nIf I knew all the ways\\n\\nThat somebody would take\\n\\nMy heart away in a moment\\n\\nIn a second how could I be happy\\n\\nIf I knew all the ways\\n\\nThat somebody would take\\n\\nMy heart away in a moment\\n\\nIn a second how could I be happy\\n\\nIf I knew all the ways\\n\\nThat somebody would take\\n\\nMy heart away in a moment\\n\\nIn a second how could I be happy\\n\\nIf I knew all the ways\\n\\nThat somebody would take\\n\\nMy heart away in a moment', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.generations[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes acceder a la información específica del proveedor que se devuelve. Sin embargo, es importante tener en cuenta que esta información no está estandarizada entre los proveedores. Cada proveedor puede proporcionar información adicional o específica que puede ser relevante para su implementación particular del modelo de lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'prompt_tokens': 120,\n",
       "  'total_tokens': 4086,\n",
       "  'completion_tokens': 3966},\n",
       " 'model_name': 'text-ada-001'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_result.llm_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Número de tokens**: También puedes estimar cuántos tokens habrá en un fragmento de texto en ese modelo. Esto es útil porque los modelos tienen una longitud de contexto (y más tokens implican un mayor costo), lo que significa que debes ser consciente de cuán extenso es el texto que estás pasando.\n",
    "\n",
    "Es importante tener en cuenta que, por defecto, los tokens se estiman utilizando \"tiktoken\" (excepto para versiones anteriores a 3.8, donde se utiliza un tokenizador de Hugging Face)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(\"what a joke\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
