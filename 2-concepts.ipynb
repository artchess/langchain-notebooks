{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptos de desarrollo de aplicaciones con LLM\n",
    "\n",
    "Los siguientes son conceptos y terminología de uso común en el desarrollo de aplicaciones LLM. \n",
    "\n",
    "## Cadena de pensamiento (CoT)\n",
    "\n",
    "La cadena de pensamiento (CoT, por sus siglas en inglés) es una técnica de sugerencia utilizada para animar al modelo a generar una serie de pasos intermedios de razonamiento. Una forma menos formal de inducir este comportamiento es incluir \"Pensemos paso a paso\" en el prompt.\n",
    "\n",
    "[Chain-of-Though Paper](https://arxiv.org/pdf/2201.11903.pdf)\n",
    "[Step-by-step Paper](https://arxiv.org/abs/2112.00114)\n",
    "\n",
    "## Generación de plan de acción\n",
    "\n",
    "La Generación de Plan de Acción es una técnica de sugerencia que utiliza un modelo de lenguaje para generar acciones a tomar. Los resultados de estas acciones pueden luego ser retroalimentados al modelo de lenguaje para generar una acción subsecuente.\n",
    "\n",
    "[WebGPT Paper](https://arxiv.org/pdf/2112.09332.pdf)\n",
    "[SayCan Paper](https://say-can.github.io/assets/palm_saycan.pdf)\n",
    "\n",
    "## ReAct\n",
    "\n",
    "ReAct es una técnica de sugerencia que combina la sugerencia en Cadena de Pensamiento con la generación de un plan de acción. Esto induce al modelo a pensar sobre qué acción tomar y luego la ejecuta.\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/2210.03629.pdf)\n",
    "[LangChain](https://python.langchain.com/en/latest/modules/agents/agents/examples/react.html)\n",
    "\n",
    "## Auto-pregunta\n",
    "\n",
    "Auto-pregunta es un método de sugerencia que se basa en la sugerencia en cadena de pensamiento. En este método, el modelo se hace explícitamente preguntas de seguimiento, las cuales son respondidas por un motor de búsqueda externo.\n",
    "\n",
    "[Paper](https://ofir.io/self-ask.pdf)\n",
    "[LangChain](https://python.langchain.com/en/latest/modules/agents/agents/examples/self_ask_with_search.html)\n",
    "\n",
    "## Encadenamiento de Sugerencias\n",
    "\n",
    "El Encadenamiento de Sugerencias consiste en combinar múltiples llamadas a LLM (Modelo de Lenguaje a Gran Escala, por sus siglas en inglés), con la salida de un paso siendo la entrada al siguiente.\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/2203.06566.pdf)\n",
    "[Language Model Cascades](https://arxiv.org/abs/2207.10342)\n",
    "[Socratic Models](https://socraticmodels.github.io/#code)\n",
    "\n",
    "\n",
    "## Proxy Memético\n",
    "\n",
    "El Proxy Memético consiste en alentar al LLM para que responda de cierta manera, enmarcando la discusión en un contexto que el modelo conoce y que resultará en ese tipo de respuesta. Por ejemplo, como una conversación entre un estudiante y un profesor.\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/2102.07350.pdf)\n",
    "\n",
    "\n",
    "## Autoconsistencia\n",
    "\n",
    "La Autoconsistencia es una estrategia de decodificación que toma muestras de un conjunto diverso de rutas de razonamiento y luego selecciona la respuesta más consistente. Es más efectiva cuando se combina con la sugerencia en Cadena de Pensamiento.\n",
    "\n",
    "[Paper](https://arxiv.org/pdf/2203.11171.pdf)\n",
    "\n",
    "\n",
    "## Incepción\n",
    "\n",
    "La Incepción, también llamada Instrucción en Primera Persona, consiste en alentar al modelo a pensar de cierta manera incluyendo el inicio de la respuesta del modelo en la sugerencia.\n",
    "\n",
    "[Ejemplo](https://twitter.com/goodside/status/1583262455207460865?s=20&t=8Hz7XBnK1OF8siQrxxCIGQ)\n",
    "\n",
    "## MemPrompt\n",
    "\n",
    "MemPrompt mantiene una memoria de errores y comentarios de los usuarios, y los utiliza para evitar la repetición de errores. \n",
    "\n",
    "[Paper](https://memprompt.com/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
